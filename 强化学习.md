1: MDP: 马尔科夫决策过程
---
	- 马尔科夫决策过程说的是一个{action, state, reward, P state transition, discount factor}的问题；状态是完全可见的，采取一个action，state会变，然后获得一个reward；注意到每个状态对应一个value function，是对未来的action导致reward的一个折现值；
	- 为什么说是马尔科夫呢，因为t+1的状态仅跟t的状态有关，跟之前的history无关
	- 一个policy说的是在已知state的情况下应该采取的action策略；
	- 部分可见的马尔科夫决策过程说的是状态不完全可见，但是当前可见的observation跟state相关，并且有个observation函数，which取决于当前的状态和上一步的action；
	- 部分可见的马尔科夫还加入了一个belief state，就是说已经知道历史观察数据(action， obvservation， reward， action， observation。。。)之后的一个隐状态分布；
	- 吐槽一下, 真不知道为什么跟分布有关的很多东西都被称作belief, 信仰？
